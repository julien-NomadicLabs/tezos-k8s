apiVersion: v1
kind: Pod
metadata:
  name: snapshot-warmer
  namespace: mainnet-shots
spec:
  serviceAccountName: snapshot-maker-sa
  containers:
    - name: snapshot-warmer
      image: 082993323195.dkr.ecr.us-east-2.amazonaws.com/snapshot-maker:latest
      command: ["/bin/sh"]
      args:
        - "-c"
        - "#!/bin/sh\n\n## Snapshot Namespace\nNAMESPACE=\"${NAMESPACE}\" yq e -i '.metadata.namespace=strenv(NAMESPACE)' createVolumeSnapshot.yaml\n\n# hangzhounet-shots PVC is called 'var-volume-archive-node' for some reason\nHISTORY_MODE=$(kubectl get pods -n \"${NAMESAPCE}\" -l appType=tezos-node -o jsonpath=\"{.items[0].metadata.labels.node_class_history_mode}\")\nif [ \"$HISTORY_MODE\" ]; then\n    PERSISTENT_VOLUME_CLAIM=var-volume-snapshot-\"${HISTORY_MODE}\"-node-0\nelse\n    PERSISTENT_VOLUME_CLAIM=var-volume-tezos-node-0\nfi\n\nPERSISTENT_VOLUME_CLAIM=\"${PERSISTENT_VOLUME_CLAIM}\" yq e -i '.spec.source.persistentVolumeClaimName=strenv(PERSISTENT_VOLUME_CLAIM)' createVolumeSnapshot.yaml\n\nwhile true; do\n\n  while [ \"$(kubectl get volumesnapshots -o jsonpath='{.items[?(.status.readyToUse==true)].metadata.name}' --namespace \"${NAMESPACE}\" -o go-template='{{len .items}}')\" -gt 4 ]; do\n    NUMBER_OF_SNAPSHOTS=$(kubectl get volumesnapshots -o jsonpath='{.items[?(.status.readyToUse==true)].metadata.name}' --namespace \"${NAMESPACE}\" -o go-template='{{len .items}}')\n    printf \"%s Number of snapshots is too high at ${NUMBER_OF_SNAPSHOTS} deleting 1.\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n    SNAPSHOTS=$(kubectl get volumesnapshots -o jsonpath='{.items[?(.status.readyToUse==true)].metadata.name}' --namespace \"${NAMESPACE}\")\n    if ! kubectl delete volumesnapshots \"${SNAPSHOTS%% *}\" --namespace \"${NAMESPACE}\"; then\n      printf \"%s ERROR deleting snapshot. ${SNAPSHOTS%% *}\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n    fi\n    sleep 10\n  done\n  \n  if ! [ \"$(kubectl get volumesnapshots -o jsonpath='{.items[?(.status.readyToUse==false)].metadata.name}' --namespace \"${NAMESPACE}\")\" ]\n  then\n    # EBS Snapshot name based on current time and date\n    SNAPSHOT_NAME=$(date \"+%Y-%m-%d-%H-%M-%S\" \"$@\")-node-snapshot\n\n    # Update volume snapshot name\n    SNAPSHOT_NAME=\"${SNAPSHOT_NAME}\" yq e -i '.metadata.name=strenv(SNAPSHOT_NAME)' createVolumeSnapshot.yaml\n\n    printf \"%s Creating snapshot ${SNAPSHOT_NAME} in ${NAMESPACE}.\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n\n    start_time=$(date +%s)\n\n    # Create snapshot\n    if ! kubectl apply -f createVolumeSnapshot.yaml\n    then\n        printf \"%s ERROR creating volumeSnapshot ${SNAPSHOT_NAME} in ${NAMESPACE} .\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n        exit 1\n    fi\n\n    sleep 5\n\n    # While no snapshots ready\n    while [ \"$(kubectl get volumesnapshots -o jsonpath='{.items[?(.status.readyToUse==false)].metadata.name}' --namespace \"${NAMESPACE}\")\" ]; do\n      printf \"%s Snapshot is still creating...\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n      sleep 5\n    done\n    end_time=$(date +%s)\n    elapsed=$(( end_time - start_time ))\n    printf \"%s Snapshot ${SNAPSHOT_NAME} in ${NAMESPACE} finished.\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n    eval \"echo Elapsed time: $(date -ud \"@$elapsed\" +'$((%s/3600/24)) days %H hr %M min %S sec')\"\n  else\n    printf \"%s Waiting for current snapshot to finish...\" \"$(date \"+%Y-%m-%d %H:%M:%S\" \"$@\")\"\n    sleep 30\n  fi\ndone        \n"
      env:
        - name: NAMESPACE
          valueFrom:
            configMapKeyRef:
              name: snapshot-configmap
              key: NAMESPACE
